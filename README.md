# GPT
a copy of the gpt file for text preprocessing 

"creating a simple Generative Pre-trained Transformer (GPT) that you can use to accept input data and give a set response. We will be making use of existing pre-trained tools that are available on HuggingFace which is a repository of various machine learning models and datasets. In particular, we will be using the MiniLM-L6-v2 transformer (https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) for our demo activity."
